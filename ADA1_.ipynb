{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba36903-ee71-4a62-9bb8-8e0270fdae64",
   "metadata": {},
   "source": [
    "# Advanced Text Analytics Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de31fe1-70a5-4357-b9d9-be40038c556c",
   "metadata": {},
   "source": [
    "This notebook is the first of two lab notebooks that you will submit as part of your assessment for the Advanced Data Analytics unit. \n",
    "\n",
    "This notebook is contains three sections:\n",
    "1. **Word embeddings:** This will introduce you to loading and training word embeddings using the Gensim library.\n",
    "2. **Introducing neural text classifiers:** Here we show you how to construct a neural network text classifier for sentiment analysis using Pytorch. \n",
    "3. **Improving neural text classifiers:** This section gives you a chance to improve the classifier from the previous section by applying what we have learned in the lectures.\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "These sections will contain tutorial-like instructions, as you have seen in previous text analytics labs. On completing these sections, the intended learning outcomes are that you will be able to...\n",
    "1. Load pretrained word embeddings models.\n",
    "1. Learn word embeddings from an unlabelled dataset.\n",
    "1. Recognise the steps required to train and test a neural text classifier with Pytorch\n",
    "1. Adapt the architecture of a neural text classifier.\n",
    "\n",
    "## Getting Started -- Python Packages\n",
    "\n",
    "Please see the README.md file for instructions on setting up your Python environment. The readme will instruct you to install the required packages, in addition to those used for Introduction to Data Analytics:\n",
    "\n",
    " * pytorch=1.9.0\n",
    " * scipy=1.8.0\n",
    " * transformers=2.1.1\n",
    "\n",
    "## Your Tasks\n",
    "\n",
    "Inside each of these sections there are several **'To-do's**, which you must complete for your summative assessment. Your marks will be based on your answers to these to-dos. Please make sure to:\n",
    "1. Include the output of your code in the saved notebook. Plots and printed output should be visible without re-running the code. \n",
    "1. Include all code needed to generate your answers.\n",
    "1. Provide sufficient comments to understand how your method works.\n",
    "1. Write text in a cell in markdown format where a written answer is required. You can convert a cell to markdown format by pressing Escape-M. \n",
    "\n",
    "There are also some unmarked 'to-do's that are part of the tutorial to help you learn how to implement and use the methods studied here. These do not contribute to your final marks.\n",
    "\n",
    "## Good Academic Practice\n",
    "\n",
    "Please follow [the guidance on academic integrity provided by the university](http://www.bristol.ac.uk/students/support/academic-advice/academic-integrity/).\n",
    "You are required to write your own answers -- do not share your notebooks or copy someone else's writing. Do not copy text or long blocks of code directly into the notebook from online sources -- always rewrite in your own way. Breaking the rules can lead to strong penalties. \n",
    "\n",
    "## Marking Criteria\n",
    "\n",
    "1. The coursework (both notebooks) is worth 30% of the unit in total. \n",
    "1. There is a total of 100 marks available for both lab notebooks. \n",
    "1. This notebook is worth 50 of those marks.\n",
    "1. The number of marks for each to-do out of 100 is shown alongside each to-do.\n",
    "1. For to-dos that require you to write code, a good solution would meet the following criteria (in order of importance):\n",
    "   1. Solves the task or answers the question asked in the to-do. This means, if the code cells in the notebook are executed in order, we will get the output shown in your notebook.\n",
    "   1. The code is easy to follow and does not contain unnecessary steps.\n",
    "   1. The comments show that you understand how your solution works.\n",
    "   1. A very good answer will also provide code that is computationally efficient but easy to read.\n",
    "1. You can use any suitable publicly available libraries. Unless the task explicitly asks you to implement something from scratch, there is no penalty for using libraries to implement some steps.\n",
    "\n",
    "## Support\n",
    "\n",
    "The main source of support will be during the remaining lab sessions (Fridays 3-6pm) for this unit. \n",
    "\n",
    "The TAs and lecturer will help you with questions about the lectures, the code provided for you in this notebook, and general questions about the topics we cover. For the marked 'to-dos', they can only answer clarifying questions about what you have to do. \n",
    "\n",
    "Office hours: You can book office hours with Edwin on Mondays 3pm-5pm by sending him an email (edwin.simpson@bristol.ac.uk). If those times are not possible for you, please contact him by email to request an alternative. \n",
    "\n",
    "## Deadline\n",
    "\n",
    "The notebook must be submitted along with the second notebook on Blackboard before **Wednesday 24th May at 13.00**. \n",
    "\n",
    "## Submission\n",
    "\n",
    "You will need to zip up this notebook and the next notebook into a single .zip file, which you will submit to Blackboard through the 'assessment, submission and feedback' link on the left sidebar. \n",
    "\n",
    "Please name your files like this:\n",
    "   * Name this notebook ADA1_<student_number>.ipynb\n",
    "   * Name the zip file <student_number>.zip\n",
    "   * Please don't include your name as we want to mark anonymously to ensure fairness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549d0b9-84d1-4d35-80b1-6341a3ea7ce6",
   "metadata": {},
   "source": [
    "# 1. Word Embeddings (max. 12 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a8852-b72a-48dd-a266-25a4bb774f6a",
   "metadata": {},
   "source": [
    "In this section we will use both sparse vectors and dense word2vec embeddings to obtain\n",
    "vector representations of words and documents. \n",
    "\n",
    "First, we will load the `tweet eval` sentiment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5519c4b9-1cac-4e8a-9e7e-a8a40b389bdf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e599bf09-ed1a-4e40-a551-2e3a889a3487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with 45615 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development/validation dataset with 2000 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (./data_cache/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset with 12284 instances loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 45615/45615 [00:02<00:00, 19783.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary has 43358 words\n",
      "Index of \"love\" is 22981\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"sentiment\",\n",
    "    split=\"train\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "print(f\"Training dataset with {len(train_dataset)} instances loaded\")\n",
    "\n",
    "\n",
    "dev_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"sentiment\",\n",
    "    split=\"validation\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "print(f\"Development/validation dataset with {len(dev_dataset)} instances loaded\")\n",
    "\n",
    "\n",
    "test_dataset = load_dataset(\n",
    "    \"tweet_eval\",\n",
    "    name=\"sentiment\",\n",
    "    split=\"test\",\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "print(f\"Test dataset with {len(test_dataset)} instances loaded\")\n",
    "\n",
    "# Put the data into lists ready for the next steps...\n",
    "train_texts = []\n",
    "train_labels = []\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    train_texts.append(train_dataset[i]['text'])\n",
    "    train_labels.append(train_dataset[i]['label'])\n",
    "            \n",
    "# HINT: A count vectorizer object may be useful in later steps\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_texts)\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = vectorizer.vocabulary_\n",
    "vocab_size = len(vocab)\n",
    "print(f'The vocabulary has {vocab_size} words')\n",
    "\n",
    "# invert the vocabulary dictionary so we can look up word types given an index\n",
    "keys = vocab.values()\n",
    "values = vocab.keys()\n",
    "vocab_inverted = dict(zip(keys, values))\n",
    "\n",
    "print(f'Index of \"love\" is {vocab[\"love\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a63c3c-d24c-4810-9c34-4532b845e310",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. Term-Document Matrix\n",
    "\n",
    "First we are going to obtain sparse word vectors from a term-document matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd30abb-0951-46ee-81a6-b9217fba6b90",
   "metadata": {},
   "source": [
    "**TO-DO 1a:** Use CountVectorizer to obtain a term-document matrix for the training set. Then, write a function that takes a word as an argument and returns its term vector from the term-document matrix you computed. Get the term vector for the word 'love'. **(4 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a52da7-89a5-41d6-bfab-83b3231d6949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (82, 0)\t1\n",
      "  (107, 0)\t1\n",
      "  (119, 0)\t1\n",
      "  (126, 0)\t1\n",
      "  (160, 0)\t1\n",
      "  (163, 0)\t1\n",
      "  (207, 0)\t1\n",
      "  (286, 0)\t1\n",
      "  (293, 0)\t1\n",
      "  (352, 0)\t1\n",
      "  (353, 0)\t1\n",
      "  (421, 0)\t1\n",
      "  (456, 0)\t1\n",
      "  (528, 0)\t1\n",
      "  (568, 0)\t1\n",
      "  (623, 0)\t1\n",
      "  (656, 0)\t1\n",
      "  (666, 0)\t1\n",
      "  (677, 0)\t1\n",
      "  (711, 0)\t1\n",
      "  (790, 0)\t1\n",
      "  (903, 0)\t1\n",
      "  (950, 0)\t1\n",
      "  (972, 0)\t1\n",
      "  (994, 0)\t1\n",
      "  :\t:\n",
      "  (44865, 0)\t1\n",
      "  (44879, 0)\t2\n",
      "  (44891, 0)\t1\n",
      "  (44916, 0)\t1\n",
      "  (44917, 0)\t1\n",
      "  (44942, 0)\t1\n",
      "  (45078, 0)\t1\n",
      "  (45105, 0)\t1\n",
      "  (45128, 0)\t1\n",
      "  (45129, 0)\t1\n",
      "  (45152, 0)\t1\n",
      "  (45161, 0)\t1\n",
      "  (45180, 0)\t1\n",
      "  (45215, 0)\t1\n",
      "  (45250, 0)\t1\n",
      "  (45254, 0)\t1\n",
      "  (45257, 0)\t1\n",
      "  (45305, 0)\t1\n",
      "  (45337, 0)\t1\n",
      "  (45373, 0)\t1\n",
      "  (45432, 0)\t1\n",
      "  (45521, 0)\t1\n",
      "  (45543, 0)\t1\n",
      "  (45600, 0)\t1\n",
      "  (45610, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "# WRITE YOUR ANSWER HERE\n",
    "#transforming the train_texts training data into a term document matrix using the vectorizer.transform function.\n",
    "term_document_matrix = vectorizer.transform(train_texts)\n",
    "\n",
    "#function that takes a word as a parameter(argument) and returns its term vector from term_document_matrix.\n",
    "def get_term_vector(word):\n",
    "    #getting the index of the word in the vocab\n",
    "    word_index = vocab[word]\n",
    "\n",
    "    #getting the term vector by selecting its column in the term_document_matrix\n",
    "    term_vector = term_document_matrix[:, word_index]\n",
    "\n",
    "    return term_vector\n",
    "\n",
    "#getting the term vector for the word 'love' and printing it\n",
    "love_term_vector = get_term_vector('love')\n",
    "print(love_term_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a286c6e1-f3e9-4c40-b968-0c24eb8dbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of words for comparison with 'love' in the next to-do.\n",
    "comparison_words = ['2wee', '4your', 'follow', 'goodnight', 'liam', 'lol', 'okay', 'sorry',\n",
    " 'wish', 'yea', 'affair', 'agree', 'all', 'alliums', 'alliumsvancouver', 'always',\n",
    " 'amazing', 'and', 'appreciate', 'ask', 'babe', 'baby', 'bandit76044', 'barat',\n",
    " 'beautiful', 'birthday', 'boy', 'bro', 'btw', 'but', 'commando', 'content',\n",
    " 'dear', 'dm', 'dream', 'dreams', 'enjoy', 'enjoyed', 'everything', 'fam',\n",
    " 'followers', 'for', 'forever', 'forget', 'friend', 'friends', 'gabrielle',\n",
    " 'girl', 'god', 'good', 'guys', 'hahaha', 'happy', 'hate', 'hello', 'hey',\n",
    " 'homework', 'hope', 'in', 'invite', 'is', 'isabel', 'it', 'jonny', 'kiss', 'know',\n",
    " 'krishna', 'ladies', 'let', 'life', 'like', 'lil', 'little', 'love', 'loved',\n",
    " 'loves', 'loving', 'lucky', 'luv', 'ma', 'may', 'me', 'mean', 'meet', 'met', 'miss',\n",
    " 'much', 'my', 'notice', 'nsfanfic', 'nuffsaid', 'nya', 'of', 'on', 'one',\n",
    " 'ontario', 'perfect', 'prefer', 'queen', 'rails', 'rather', 'recommend',\n",
    " 'remember', 'see', 'share', 'sing', 'smile', 'so', 'suggest', 'sunat', 'sweet',\n",
    " 'tag', 'tail', 'tebaklagu', 'thank', 'thanks', 'the', 'this', 'thsoul', 'to',\n",
    " 'tomorrow', 'too', 'true', 'unreservedly', 'user', 'want', 'weed', 'what', 'wish',\n",
    " 'wishes', 'with', 'women_of_christ', 'would', 'wow', 'xxxxxx', 'yay', 'yes',\n",
    " 'you', 'your', 'zorro',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb324d8-a92a-4fd7-bd7f-f3b0f0958e6b",
   "metadata": {},
   "source": [
    "**TO-DO 1b:** Write a function that computes the similarity between two different term vectors. For this to-do, do not simply call a library function that implements a similarity function, implement the calculation yourself. Use the function to find the five most similar terms to \"love\" from the list of `comparison_words` given above. **(6 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4574ad75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar words to 'love' are: [('love', 1.0), ('you', 0.14170441974255654), ('user', 0.09879910847998889), ('the', 0.08769922256389782), ('and', 0.08543046072802546)]\n"
     ]
    }
   ],
   "source": [
    "#creating a similarity function that takes in 2 parameters vec1 and vec2\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    #computing dot product of both vectors\n",
    "    dot_product = vec1.dot(vec2)\n",
    "    \n",
    "    #computing the L2 norm of each vector\n",
    "    vec1_norm = np.linalg.norm(vec1)\n",
    "    vec2_norm = np.linalg.norm(vec2)\n",
    "    \n",
    "    #computing cosine sim\n",
    "    similarity = dot_product / (vec1_norm * vec2_norm)\n",
    "    return similarity\n",
    "\n",
    "#creating another function that takes a target word, which is 'love' in this case and compares it to the top 5 most\n",
    "#similar words, n=5 is default\n",
    "def get_top_similar_words(target_word, comparison_words, top_n=5):\n",
    "    #creating an empty list that stores the similatities between target and comparison word vector\n",
    "    target_term_vector = get_term_vector(target_word)\n",
    "    similarities = []\n",
    "    \n",
    "    #looping through each word in comparison_words and calculating the cosine similarity between target and comparison\n",
    "    #words term vector and appending a tuple of the comparison word and its similarity score to the similarities list.\n",
    "    for word in comparison_words:\n",
    "        try:\n",
    "            term_vector = get_term_vector(word)\n",
    "            similarity = cosine_similarity(target_term_vector.toarray().flatten(), term_vector.toarray().flatten())\n",
    "            similarities.append((word, similarity))\n",
    "        except KeyError:\n",
    "            #if the word is not in the vocabulary, skip it\n",
    "            pass\n",
    "\n",
    "    #sorting the list of tuples by similarity and getting the top n words, n = 5 in this case\n",
    "    top_similar_words = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    return top_similar_words\n",
    "\n",
    "#printing out the 5 most similar words to 'love'\n",
    "top_5_similar_words = get_top_similar_words('love', comparison_words)\n",
    "print(f\"The 5 most similar words to 'love' are: {top_5_similar_words}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9654fde-cbe7-4020-99f7-49d97b4eacfa",
   "metadata": {},
   "source": [
    "## 1.2 Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e772ce7-853e-478d-9d0a-3f591100e88d",
   "metadata": {},
   "source": [
    "Now, we will use Gensim to train a word2vec model. The code below tokenizes the training texts, then runs word2vec (the skipgram model) to learn a set of embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5d13e1-683f-41f6-bf24-7c036aef59fa",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "tokenized_texts = [list(tokenize(text)) for text in train_texts]\n",
    "emb_model = word2vec.Word2Vec(tokenized_texts, sg=1, min_count=1, window=3, vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989624ac-dc98-461f-a5ad-c28cf27ca085",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the word vector for 'love'\n",
    "love_embedding = emb_model.wv['love']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd66ea-cbbe-4c1a-a467-5a784facf33b",
   "metadata": {},
   "source": [
    "**TODO 1c:** Find the five most similar words to 'love' according to your word2vec model. You can use the Gensim function `similar_by_word` to do this. How does the Word2Vec top 5 differ from the top 5 comparison words found using the term-document matrix? **(2 marks)**\n",
    "\n",
    "WRITE YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc37a093-db74-4e10-9224-0740381b30fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar words to 'love' using the Word2Vec model are: [('appreciate', 0.8397475481033325), ('Wish', 0.8390538096427917), ('thank', 0.8379523158073425), ('dear', 0.8345212936401367), ('wish', 0.8302745223045349)]\n"
     ]
    }
   ],
   "source": [
    "# WRITE YOUR OWN CODE HERE\n",
    "top_5_similar_words = emb_model.wv.similar_by_word('love', topn=5)\n",
    "print(f\"The 5 most similar words to 'love' using the Word2Vec model are: {top_5_similar_words}\")\n",
    "\n",
    "#The top 5 for the Word2Vec does differ from the top 5 using the term-dcoument matrix. This is most likely because \n",
    "#the Word2Vec is trained to capture more semantic relationships between the words whereas the term-document matrix may\n",
    "#capture words that appear in similar contexts as the word 'love' due to its matrix format representing the frequency\n",
    "#of occurences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28de29-ee93-47e9-ba62-de7771d7203d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Above, we trained our own model using the skipgram method. We can also download a pretrained model that has previously been trained on a large corpus. There is a list of models available [here](https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models). Let's try out GLoVe embeddings. GLoVe is an alternative to the skipgram model. This model was trained on a corpus of tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693126a6-519a-44c1-b800-773fc95d38df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.62645  -0.082389  0.070538  0.5782   -0.87199  -0.14816   2.2315\n",
      "  0.98573  -1.3154   -0.34921  -0.8847    0.14585  -4.97     -0.73369\n",
      " -0.94359   0.035859 -0.026733 -0.77538  -0.30014   0.48853  -0.16678\n",
      " -0.016651 -0.53164   0.64236  -0.10922 ]\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "\n",
    "glove_wv = gensim.downloader.load('glove-twitter-25')\n",
    "\n",
    "# show the vector for Hamlet:\n",
    "print(glove_wv['love'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcbeb21-549d-4315-bce1-e785cda13fd2",
   "metadata": {},
   "source": [
    "TODO 1d: Find the most similar five words to 'happy' according to the GloVe Twitter model. (this task is unmarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6893470a-08b7-4f44-b5f0-8faddb91ae85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar words to 'happy' using the GloVe Twitter model are: [('birthday', 0.9577818512916565), ('thank', 0.937666654586792), ('welcome', 0.93361496925354), ('love', 0.917618453502655), ('miss', 0.9164499640464783)]\n"
     ]
    }
   ],
   "source": [
    "#printing out the top 5 most similar words to 'happy' using the GloVe model\n",
    "top_5_similar_words = glove_wv.most_similar('happy', topn=5)\n",
    "print(f\"The 5 most similar words to 'happy' using the GloVe Twitter model are: {top_5_similar_words}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc39168a-7b01-4171-beb2-8a4bf035fd71",
   "metadata": {},
   "source": [
    "Notice again that a different set of words are favoured than with word2vec or term-document vectors, and consider how this might result from pretraining the embeddings on Twitter data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d24e4-d90d-4f50-a167-5f4876076355",
   "metadata": {},
   "source": [
    "# 2. Introducing Neural Text Classifiers (max. 16 marks)\n",
    "\n",
    "This section shows you how to implement a neural network classifier using Pytorch and leads you through the steps required to process text sequences.\n",
    "\n",
    "There are several big advantages to building a text classifier using a neural network:\n",
    "   * It can model nonlinear functions, so can handle much more complex relationships between features and class labels.\n",
    "   * It performs representation learning: the hidden layers learn how to extract features from low-level data.\n",
    "   * It can process sequences of tokens -- we don't have to think in terms of a single feature vector representing a document as we did for logistic regression.\n",
    "  \n",
    "The downsides are:\n",
    "   * Much more expensive to train and test.\n",
    "   * It can overfit very badly to small datasets.\n",
    "   * The features learned by the hidden layers can be hard to interpret, which can make it hard to predict the model's behaviour, e.g., what sort of cases it may fail on.\n",
    "   \n",
    "Let's start by building a neural network text classifier that takes a sequence of tokens as input, and predicts a class label. For simplicity, it will use a single fully connected feedforward layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4f88e-bd86-4917-8e9d-26ace635873e",
   "metadata": {},
   "source": [
    "\n",
    "We are going to construct the neural network in this form:\n",
    "\n",
    "<img src=\"neural_text_classifier_smaller.png\" alt=\"Neural text classifier diagram\" width=\"600px\"/>\n",
    "\n",
    "The first step -- as always -- is to get our data into the right format. We start from a set of tokenised documents (in this case, tweets), where each document is represented as a sequence of text tokens. The neural network cannot process the tokens as strings, so we need to convert each token to a numerical input value. The input value for each token is used to look up the corresponding embedding in the embedding layer. For PyTorch, it's not necessary to create one-hot vectors for each token, as library just uses the indexes of the words in the vocabulary to look up the corresponding word embedding. \n",
    "\n",
    "So, let's now map the tokens to their IDs -- their indexes in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a71101-e504-42a8-9862-74796af52cd0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function encode_text at 0x194985ee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5343e53e25494dbcb63a116aa0ba04c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "45615"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize training set and convert to input IDs.\n",
    "def encode_text(sample):\n",
    "    tokens = tokenize(sample['text'])  # Tokenize one document\n",
    "    \n",
    "    input_ids = []\n",
    "    for token in tokens:\n",
    "        if str.lower(token) in vocab:  # Skip words from the dev/test set that are not in the vocabulary.\n",
    "            input_ids.append(vocab[str.lower(token)]+1) # +1 is needed because we reserve 0 as a special character\n",
    "            \n",
    "    sample['input_ids'] = input_ids \n",
    "    return sample\n",
    "\n",
    "# The map method of the dataset object takes a function as its argument, \n",
    "# and applies that function to each document in the dataset.\n",
    "train_dataset = train_dataset.map(encode_text)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce8d8c-ce83-49b7-9b88-b84233be7dbf",
   "metadata": {},
   "source": [
    "Our neural network's input layer has a fixed size, so we need to make all of our documents have the same number of tokens. Let's plot a histogram to understand the length distribution of the texts in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "832da949-3fec-4d26-936e-23c943546b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the document length: 18.160166611860134\n",
      "Median of the document length: 18.0\n",
      "Maximum document length: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   21.,   522.,  2430.,  4908.,  7772., 11003., 10389.,  6738.,\n",
       "         1719.,   113.]),\n",
       " array([ 1. ,  4.1,  7.2, 10.3, 13.4, 16.5, 19.6, 22.7, 25.8, 28.9, 32. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rv_l = [len(doc) for doc in train_dataset['input_ids']]\n",
    "print('Mean of the document length: {}'.format(np.mean(rv_l)))\n",
    "print('Median of the document length: {}'.format(np.median(rv_l)))\n",
    "print('Maximum document length: {}'.format(np.max(rv_l)))\n",
    "\n",
    "plt.hist(rv_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97d92c-7002-4b63-9011-8ed21ea52e95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now neeed to choose a fixed sequence length, then *pad* the documents that are shorter than this maximum by adding a special token to the start of the sequence. The special pad token has an input value of 0. Any documents that exceed the length will be truncated.\n",
    "\n",
    "**TO-DO 2a:** Complete the padding code below to insert 0s at the start of any sequences that are too short, and to truncate any sequences that are too long. **(3 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8488dfa-61b8-438e-92ee-7f9b84b27a68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c63391a7b5a4994b39db9e1632f9d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequence_length = 40  # truncate all docs longer than this. Pad all docs shorter than this.\n",
    "\n",
    "def pad_text(sample):\n",
    "    input_ids = sample['input_ids']\n",
    "\n",
    "    #if the input sequence is longer than the maximum length, truncate it\n",
    "    if len(input_ids) > sequence_length:\n",
    "        input_ids = input_ids[:sequence_length]\n",
    "    \n",
    "    #if the input sequence is shorter than the maximum length, pad it with 0s at the beginning\n",
    "    if len(input_ids) < sequence_length:\n",
    "        padding = [0] * (sequence_length - len(input_ids))\n",
    "        input_ids = padding + input_ids\n",
    "    \n",
    "    #updating the 'input_ids' key-value pair in the sample with the padded/truncated sequence\n",
    "    sample['input_ids'] = input_ids\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# The map method will call pad_text for every document in the dataset\n",
    "train_dataset = train_dataset.map(pad_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb33a1-ca74-4a95-bbd5-2b9e50167733",
   "metadata": {},
   "source": [
    "We now have our data in almost the right format! To train a model using PyTorch, we are going to wrap our dataset in a [DataLoader object](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). This allows the training process to select random subsets of the dataset -- mini-batches -- which it will use for learning with mini-batch stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ab3c226-402b-4eb5-8f9a-fe216b4c5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# convert from the Huggingface format to a TensorDataset so we can use the mini-batch sampling functionality\n",
    "def convert_to_data_loader(dataset, num_classes):\n",
    "    # convert from list to tensor\n",
    "    input_tensor = torch.from_numpy(np.array(dataset['input_ids']))\n",
    "    label_tensor = torch.from_numpy(np.array(dataset['label'])).long()\n",
    "    tensor_dataset = TensorDataset(input_tensor, label_tensor)\n",
    "    loader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "num_classes = len(np.unique(train_labels))   # number of possible labels in the sentiment analysis task\n",
    "\n",
    "train_loader = convert_to_data_loader(train_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5825c-4a0e-4fc8-9de6-504bc7227377",
   "metadata": {},
   "source": [
    "Let's process the development and test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78aa6ddc-b936-431c-865e-dc55eaf3086c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc50736f6b24cc8838bf052402403f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7b3157de47417e94474020ac15de8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aac6c28eec4dd2afb703333b31b2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a730f5c3e2471f8b92b6ad5da94c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev_dataset = dev_dataset.map(encode_text)\n",
    "dev_dataset = dev_dataset.map(pad_text)\n",
    "dev_loader = convert_to_data_loader(dev_dataset, num_classes)\n",
    "\n",
    "test_dataset = test_dataset.map(encode_text)\n",
    "test_dataset = test_dataset.map(pad_text)\n",
    "test_loader = convert_to_data_loader(test_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b857f-5d57-44fd-a1b4-e1b31a009c72",
   "metadata": {},
   "source": [
    "As shown in the diagram above, we will build a NN with three different layers for sentiment classification.\n",
    "\n",
    "### Embedding layer\n",
    "In the embedding layer, the network will create its own embeddings for the index with a given embedding dimension.\n",
    "The module `nn.Embedding()` creates a simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "This module is often used to store word embeddings and retrieve them using indices.\n",
    "The module's input is a list of indices, and the output is the corresponding word embeddings.\n",
    "\n",
    "[Documentation for Embedding Class](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "\n",
    "### Fully-connected layer\n",
    "Fully-connected layers in a neural network are those layers where all the inputs from the previous layer are connected to every unit of the fully-connected layer. Here we will use fully-connected layers for the hidden layer and output layer. In Pytorch this kind of layer is implemented by the 'Linear' class:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "## Activation functions\n",
    "In Pytorch, the activation function is not included in the Linear class (or other kinds of neural network layer), so we need to explicitly connect each layer to an activation function.\n",
    "In Pytorch, we construct a neural network by connecting up the output of each component to the input of the next, thereby creating a computation graph.\n",
    "To complete the hidden layer, we connect the ouput of the linear layer to a ReLU activation function, thereby creating a nonlinear function.\n",
    "\n",
    "The cell below defines a class for our neural text classifier. The constructor creates each of the layers and the activations. The dimensions of each layer need to be correct so that the output of one layer can be passed as input to the next, but the code is not yet complete.\n",
    "\n",
    "Below the constructor is the forward method. This is called in the 'forward pass' to map the neural network's inputs to its outputs. In PyTorch, we pass data through each layer of the model, connecting them together, then returning the output of the final layer.\n",
    "\n",
    "**TO-DO 2b** Complete the constructor and the forward method below for a NN with three layers. The places where you need to add code are marked in the cell below. Refer to the Pytorch documentation for additional help.  **(2 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e38a13cf-4b4d-4ac2-868c-8ad5c1b72b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FFTextClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, sequence_length, embedding_size, hidden_size, num_classes):\n",
    "        super(FFTextClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # Here we just need to construct the components of our network. We don't need to connect them together yet.\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_size) # embedding layer\n",
    "        \n",
    "        ### COMPLETE THE CODE HERE: WRITE IN THE MISSING ARGUMENTS SPECIFYING THE DIMENSIONS OF EACH LAYER\n",
    "        self.hidden_layer = nn.Linear(sequence_length*embedding_size, hidden_size) # Fully connected hidden layer\n",
    "        self.activation = nn.ReLU() # Hidden layer\n",
    "        \n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes) # Fully connected output layer\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward (self, input_words):\n",
    "        # Input dimensions are:  (batch_size, seq_length)\n",
    "        embedded_words = self.embedding_layer(input_words)  # (batch_size, seq_length, embedding_size)\n",
    "\n",
    "        # flatten the sequence of embedding vectors for each document into a single vector.\n",
    "        embedded_words = embedded_words.reshape(embedded_words.shape[0], sequence_length*self.embedding_size)  # batch_size, seq_length*embedding_size\n",
    "\n",
    "        z = self.hidden_layer(embedded_words)   # (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        h = self.activation(z)\n",
    "\n",
    "        output = self.output_layer(h)                      # (batch_size, num_classes)\n",
    "\n",
    "        # Notice we haven't applied a softmax activation to the output layer -- it's not required by Pytorch's loss function.\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f22db-b953-4f98-920f-3f9a2b1e3707",
   "metadata": {},
   "source": [
    "Now the class is complete. \n",
    "\n",
    "TO-DO 2c: In the next cell, create a NN with the FFTextClassifier class we wrote. (unmarked)\n",
    "\n",
    "Hint: `ff_classifier_model = FFTextClassifier(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a52d795a-adbc-4c48-aadf-f911520ac42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vectorizer.vocabulary_) + 1\n",
    "embedding_size = 10  # number of dimensions for embeddings\n",
    "hidden_size = 8 # number of hidden units\n",
    "\n",
    "###WRITE YOUR OWN CODE HERE\n",
    "\n",
    "#creating a neural network with the FFTextClassifier from above\n",
    "ff_classifier_model = FFTextClassifier(vocab_size, sequence_length, embedding_size, hidden_size, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6c48d-f2b4-45e6-838e-d08c895f7e86",
   "metadata": {},
   "source": [
    "After desigining our network, we need to create a training function to calculate the loss for each input and perform backpropagation to optimise the network.\n",
    "During training, the weights of all the layers will be updated.\n",
    "\n",
    "Below, we build a training function to train the NN over a fixed number of epochs (an epoch is one iteration over the whole training dataset).\n",
    "The function also prints the performance of both training and development/validation set after each epoch.\n",
    "\n",
    "Here we use cross-entropy loss, which is the standard loss function for classification that we also used for logistic regression. The module `nn.CrossEntropyLoss()` operates directly on the output of our output layer, so we don't have to implement the softmax layer within the forward() method.\n",
    "\n",
    "Cross Entropy Loss: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "\n",
    "The optimizer object implements a particular algorithm for updating the weights. Here, we will use the Adam optimizer, which is a variant of stochastic gradient descent method that tends to find a better solution in a smaller number of iterations than standard SGD.\n",
    "\n",
    "Optimization: https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "The cell below defines a training function for our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c682c18-b30c-489f-9c22-fb5662fc7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def train_nn(num_epochs, model, train_dataloader, dev_dataloader):\n",
    "    \n",
    "    learning_rate = 0.0005  # learning rate for the gradient descent optimizer, related to the step size\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()  # create loss function object\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # create the optimizer\n",
    "    train_losses_epoch = []\n",
    "    dev_losses_epoch = []\n",
    "        \n",
    "    for e in range(num_epochs):\n",
    "        # Track performance on the training set as we are learning...\n",
    "        total_correct = 0\n",
    "        total_trained = 0\n",
    "        train_losses = []\n",
    "        \n",
    "\n",
    "        model.train()  # Put the model in training mode.\n",
    "        \n",
    "        train_losses_epoch.append(np.mean(train_losses))\n",
    "        dev_losses_epoch.append(np.mean(dev_losses))\n",
    "\n",
    "        for i, (batch_input_ids, batch_labels) in enumerate(train_dataloader):\n",
    "            # Iterate over each batch of data\n",
    "            # print(f'batch no. = {i}')\n",
    "\n",
    "            optimizer.zero_grad()  # Reset the optimizer\n",
    "\n",
    "            # Use the model to perform forward inference on the input data.\n",
    "            # This will run the forward() function.\n",
    "            output = model(batch_input_ids)\n",
    "\n",
    "            # Compute the loss for the current batch of data\n",
    "            batch_loss = loss_fn(output, batch_labels)\n",
    "\n",
    "            # Perform back propagation to compute the gradients with respect to each weight\n",
    "            batch_loss.backward()\n",
    "\n",
    "            # Update the weights using the compute gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Record the loss from this sample to keep track of progress.\n",
    "            train_losses.append(batch_loss.item())\n",
    "\n",
    "            # Count correct labels so we can compute accuracy on the training set\n",
    "            predicted_labels = output.argmax(1)\n",
    "            total_correct += (predicted_labels == batch_labels).sum().item()\n",
    "            total_trained += batch_labels.size(0)\n",
    "\n",
    "        train_accuracy = total_correct/total_trained*100\n",
    "\n",
    "        print(\"Epoch: {}/{}\".format((e+1), num_epochs),\n",
    "              \"Training Loss: {:.4f}\".format(np.mean(train_losses)),\n",
    "              \"Training Accuracy: {:.4f}%\".format(train_accuracy))\n",
    "        \n",
    "        # Compute accuracy on dev set after this training epoch\n",
    "        \n",
    "        model.eval()  # Switch model to evaluation mode - turn off any random steps such as dropout\n",
    "        total_correct = 0\n",
    "        total_trained = 0\n",
    "        dev_losses = []\n",
    "\n",
    "        for dev_input_ids, dev_labels in dev_dataloader:\n",
    "            dev_output = model(dev_input_ids)\n",
    "            batch_loss = loss_fn(dev_output, dev_labels)\n",
    "            dev_losses.append(batch_loss.item()) \n",
    "            \n",
    "            # Count the number of correct predictions\n",
    "            predicted_labels = dev_output.argmax(1)\n",
    "            total_correct += (predicted_labels == dev_labels).sum().item()\n",
    "            total_trained += dev_labels.size(0)\n",
    "            \n",
    "        dev_accuracy = total_correct/total_trained*100\n",
    "        \n",
    "        print(\"Epoch: {}/{}\".format((e+1), num_epochs),\n",
    "              \"Validation Loss: {:.4f}\".format(np.mean(dev_losses)),\n",
    "              \"Validation Accuracy: {:.4f}%\".format(dev_accuracy))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e335655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(num_epochs, model, train_dataloader, dev_dataloader):\n",
    "    \n",
    "    learning_rate = 0.0005  # learning rate for the gradient descent optimizer, related to the step size\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()  # create loss function object\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # create the optimizer\n",
    "    \n",
    "    train_losses_epoch = []\n",
    "    dev_losses_epoch = []\n",
    "        \n",
    "    for e in range(num_epochs):\n",
    "        # Track performance on the training set as we are learning...\n",
    "        total_correct = 0\n",
    "        total_trained = 0\n",
    "        train_losses = []\n",
    "\n",
    "        model.train()  # Put the model in training mode.\n",
    "\n",
    "        for i, (batch_input_ids, batch_labels) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_input_ids)\n",
    "            batch_loss = loss_fn(output, batch_labels)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(batch_loss.item())\n",
    "\n",
    "            predicted_labels = output.argmax(1)\n",
    "            total_correct += (predicted_labels == batch_labels).sum().item()\n",
    "            total_trained += batch_labels.size(0)\n",
    "\n",
    "        train_accuracy = total_correct / total_trained * 100\n",
    "        train_losses_epoch.append(np.mean(train_losses))\n",
    "\n",
    "        print(\"Epoch: {}/{}\".format((e+1), num_epochs),\n",
    "              \"Training Loss: {:.4f}\".format(np.mean(train_losses)),\n",
    "              \"Training Accuracy: {:.4f}%\".format(train_accuracy))\n",
    "        \n",
    "        # Compute accuracy on dev set after this training epoch\n",
    "        \n",
    "        model.eval()  # Switch model to evaluation mode - turn off any random steps such as dropout\n",
    "        total_correct = 0\n",
    "        total_trained = 0\n",
    "        dev_losses = []\n",
    "\n",
    "        for dev_input_ids, dev_labels in dev_dataloader:\n",
    "            dev_output = model(dev_input_ids)\n",
    "            batch_loss = loss_fn(dev_output, dev_labels)\n",
    "            dev_losses.append(batch_loss.item()) \n",
    "            \n",
    "            predicted_labels = dev_output.argmax(1)\n",
    "            total_correct += (predicted_labels == dev_labels).sum().item()\n",
    "            total_trained += dev_labels.size(0)\n",
    "            \n",
    "        dev_accuracy = total_correct / total_trained * 100\n",
    "        dev_losses_epoch.append(np.mean(dev_losses))\n",
    "        \n",
    "        print(\"Epoch: {}/{}\".format((e+1), num_epochs),\n",
    "              \"Validation Loss: {:.4f}\".format(np.mean(dev_losses)),\n",
    "              \"Validation Accuracy: {:.4f}%\".format(dev_accuracy))\n",
    "\n",
    "    return model, train_losses_epoch, dev_losses_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473f92-78d4-4a5d-94cc-749165e3896e",
   "metadata": {},
   "source": [
    "**TO-DO 2d:** Modify the training function above to return the training and development (or 'validation') losses at each epoch. Train the network for 15 epochs and plot the losses. Describe what the plot shows, and how you could use this information to improve the training process. **(8 marks)**\n",
    "\n",
    "EXPLAIN YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ac7c289-fae8-4045-b18c-8db7e678214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15 Training Loss: 1.0140 Training Accuracy: 44.6695%\n",
      "Epoch: 1/15 Validation Loss: 1.0109 Validation Accuracy: 45.1000%\n",
      "Epoch: 2/15 Training Loss: 0.9982 Training Accuracy: 47.7891%\n",
      "Epoch: 2/15 Validation Loss: 1.0006 Validation Accuracy: 46.9000%\n",
      "Epoch: 3/15 Training Loss: 0.9737 Training Accuracy: 51.0161%\n",
      "Epoch: 3/15 Validation Loss: 0.9813 Validation Accuracy: 49.4500%\n",
      "Epoch: 4/15 Training Loss: 0.9422 Training Accuracy: 53.6402%\n",
      "Epoch: 4/15 Validation Loss: 0.9582 Validation Accuracy: 50.4000%\n",
      "Epoch: 5/15 Training Loss: 0.9108 Training Accuracy: 56.0605%\n",
      "Epoch: 5/15 Validation Loss: 0.9520 Validation Accuracy: 51.3000%\n",
      "Epoch: 6/15 Training Loss: 0.8819 Training Accuracy: 57.8735%\n",
      "Epoch: 6/15 Validation Loss: 0.9299 Validation Accuracy: 54.1000%\n",
      "Epoch: 7/15 Training Loss: 0.8545 Training Accuracy: 59.5265%\n",
      "Epoch: 7/15 Validation Loss: 0.9197 Validation Accuracy: 55.0000%\n",
      "Epoch: 8/15 Training Loss: 0.8290 Training Accuracy: 61.0830%\n",
      "Epoch: 8/15 Validation Loss: 0.9067 Validation Accuracy: 55.9000%\n",
      "Epoch: 9/15 Training Loss: 0.8048 Training Accuracy: 62.4729%\n",
      "Epoch: 9/15 Validation Loss: 0.8956 Validation Accuracy: 56.1500%\n",
      "Epoch: 10/15 Training Loss: 0.7820 Training Accuracy: 63.6457%\n",
      "Epoch: 10/15 Validation Loss: 0.8853 Validation Accuracy: 57.5000%\n",
      "Epoch: 11/15 Training Loss: 0.7614 Training Accuracy: 65.0860%\n",
      "Epoch: 11/15 Validation Loss: 0.8857 Validation Accuracy: 57.6000%\n",
      "Epoch: 12/15 Training Loss: 0.7414 Training Accuracy: 66.3422%\n",
      "Epoch: 12/15 Validation Loss: 0.8821 Validation Accuracy: 58.7000%\n",
      "Epoch: 13/15 Training Loss: 0.7219 Training Accuracy: 67.4274%\n",
      "Epoch: 13/15 Validation Loss: 0.8999 Validation Accuracy: 60.0000%\n",
      "Epoch: 14/15 Training Loss: 0.7047 Training Accuracy: 68.4073%\n",
      "Epoch: 14/15 Validation Loss: 0.8862 Validation Accuracy: 59.9000%\n",
      "Epoch: 15/15 Training Loss: 0.6870 Training Accuracy: 69.3127%\n",
      "Epoch: 15/15 Validation Loss: 0.8811 Validation Accuracy: 60.8000%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###WRITE YOUR OWN CODE HERE\n",
    "\n",
    "#setting the number of epochs to 15 \n",
    "num_epochs = 15\n",
    "\n",
    "#initiliasing and instance of the FFTextClassifier class and training the model using the train_nn function\n",
    "ff_classifier_model = FFTextClassifier(vocab_size, sequence_length, embedding_size, hidden_size, num_classes)\n",
    "trained_model, train_losses, dev_losses = train_nn(num_epochs, ff_classifier_model, train_loader, dev_loader)\n",
    "\n",
    "#plotting the training and validation losses over the epochs\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs+1), dev_losses, label='Dev Loss')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655f07b-c687-4d9b-a0b3-44f0d3ccbead",
   "metadata": {},
   "source": [
    "The code below obtains predictions from our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf4368a8-57fc-4cd3-b74e-aa385105c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(trained_model, test_loader):\n",
    "\n",
    "    trained_model.eval()  # switch off some randomisation used during training (dropout) to give consistent predictions\n",
    "\n",
    "    correct = 0  # count the number of correct classification labels\n",
    "\n",
    "    gold_labs = []  # gold labels to return\n",
    "    pred_labs = []  # predicted labels to return\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        test_output = trained_model(inputs)  # run the forward() function on the inputs\n",
    "        predicted_labels = test_output.argmax(1)  # select the class labels with highest logits as our predictions\n",
    "\n",
    "        gold_labs.extend(labels.tolist())\n",
    "        pred_labs.extend(predicted_labels.tolist())\n",
    "    \n",
    "    return gold_labs, pred_labs\n",
    "\n",
    "gold_labs, pred_labs = predict_nn(trained_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5620658-9e5a-4248-aa48-3e3868011aaf",
   "metadata": {},
   "source": [
    "Now, we can use pretrained word embeddings instead of learning them from scratch during training.\n",
    "Here, we will use the pretrained GloVe embeddings that we loaded before. The embedding matrix is used to initialise the embedding layer. The code below converts the GloVe embeddings into an embedding matrix suitable for PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "872638e9-f86c-48e4-8745-9c667e250a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/hw1cdj5x7bb_klmnn8kzz_rc0000gn/T/ipykernel_12879/225966899.py:5: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1678402353079/work/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  embedding_matrix[word_idx, :] = torch.from_numpy(glove_wv[word])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.3535,  0.0987,  0.1718,  ...,  0.4630,  1.3101,  1.1314],\n",
      "        [-0.4106,  0.1487,  0.0637,  ...,  0.6097,  1.0935,  0.9614],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = torch.zeros((vocab_size, glove_wv.vector_size))\n",
    "for word in vocab:\n",
    "    word_idx = vocab[word]\n",
    "    if word in glove_wv:\n",
    "        embedding_matrix[word_idx, :] = torch.from_numpy(glove_wv[word])\n",
    "        \n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e7656-343f-449c-9329-411ad7fb22d5",
   "metadata": {},
   "source": [
    "The class below extends the FFTextClassifier class (it's incomplete for now -- you'll fix this in a minute!). This means that it inherits all of its functionality, but we overwrite the constructor (the `__init__` method). This way, we don't need to define the forward function again, as it will be the same as before.\n",
    "\n",
    "The embedding layer is now different as it loads pretrained embeddings from our matrix. The argument `freeze` determines whether the embeddings remain fixed to their pretrained values (if `freeze=True`) or are updated through backpropagation to fit them to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b93f97-57b9-4d3b-a36f-547d472e1f37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FFTextClassifierWithEmbeddings(FFTextClassifier):\n",
    "\n",
    "    def __init__(self, hidden_size, sequence_length, num_classes, embedding_matrix):\n",
    "        super(FFTextClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_matrix.shape[1] \n",
    "\n",
    "        # Here we just need to construct the components of our network. We don't need to connect them together yet.\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=True) # embedding layer\n",
    "\n",
    "        ### COMPLETE THE ARGUMENTS TO SPECIFY THE DIMENSIONS OF THE LAYERS\n",
    "        self.hidden_layer = nn.Linear(sequence_length * self.embedding_size, hidden_size) # Hidden layer\n",
    "        self.activation = nn.ReLU() # Hidden layer activation\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes) # Fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae91af-4e37-476d-ba7d-709924bb329c",
   "metadata": {},
   "source": [
    "**TO-DO 2e:** Complete the arguments in the `FFTextClassifierWithEmbeddings` constructor to set the dimensions of the neural network layers.  Repeat the experiment above using the FFTextClassifierWithEmbeddings with the GLoVe embeddings. Choose a suitable performance metric and compare the performance of the two neural text classifiers. Explain in one or two sentences the possible reason(s) for any performance differences you observe. **(3 marks)**\n",
    "\n",
    "WRITE YOUR ANSWER HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73d4afd4-a92d-468d-a6ea-e693c10de36d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15 Training Loss: 1.0103 Training Accuracy: 46.7127%\n",
      "Epoch: 1/15 Validation Loss: 0.9985 Validation Accuracy: 48.2000%\n",
      "Epoch: 2/15 Training Loss: 0.9785 Training Accuracy: 49.2426%\n",
      "Epoch: 2/15 Validation Loss: 0.9924 Validation Accuracy: 46.7000%\n",
      "Epoch: 3/15 Training Loss: 0.9650 Training Accuracy: 50.2401%\n",
      "Epoch: 3/15 Validation Loss: 0.9876 Validation Accuracy: 47.3000%\n",
      "Epoch: 4/15 Training Loss: 0.9572 Training Accuracy: 50.9043%\n",
      "Epoch: 4/15 Validation Loss: 0.9949 Validation Accuracy: 47.1000%\n",
      "Epoch: 5/15 Training Loss: 0.9513 Training Accuracy: 51.6321%\n",
      "Epoch: 5/15 Validation Loss: 0.9907 Validation Accuracy: 47.4500%\n",
      "Epoch: 6/15 Training Loss: 0.9462 Training Accuracy: 51.9807%\n",
      "Epoch: 6/15 Validation Loss: 0.9896 Validation Accuracy: 46.4000%\n",
      "Epoch: 7/15 Training Loss: 0.9416 Training Accuracy: 52.3709%\n",
      "Epoch: 7/15 Validation Loss: 1.0018 Validation Accuracy: 46.8500%\n",
      "Epoch: 8/15 Training Loss: 0.9378 Training Accuracy: 52.7524%\n",
      "Epoch: 8/15 Validation Loss: 1.0040 Validation Accuracy: 47.2500%\n",
      "Epoch: 9/15 Training Loss: 0.9339 Training Accuracy: 53.0198%\n",
      "Epoch: 9/15 Validation Loss: 1.0073 Validation Accuracy: 46.6500%\n",
      "Epoch: 10/15 Training Loss: 0.9306 Training Accuracy: 53.2654%\n",
      "Epoch: 10/15 Validation Loss: 1.0085 Validation Accuracy: 46.8000%\n",
      "Epoch: 11/15 Training Loss: 0.9273 Training Accuracy: 53.7608%\n",
      "Epoch: 11/15 Validation Loss: 1.0163 Validation Accuracy: 47.0500%\n",
      "Epoch: 12/15 Training Loss: 0.9246 Training Accuracy: 53.9559%\n",
      "Epoch: 12/15 Validation Loss: 1.0101 Validation Accuracy: 47.3000%\n",
      "Epoch: 13/15 Training Loss: 0.9217 Training Accuracy: 54.2278%\n",
      "Epoch: 13/15 Validation Loss: 1.0186 Validation Accuracy: 46.9000%\n",
      "Epoch: 14/15 Training Loss: 0.9196 Training Accuracy: 54.5150%\n",
      "Epoch: 14/15 Validation Loss: 1.0211 Validation Accuracy: 47.3000%\n",
      "Epoch: 15/15 Training Loss: 0.9172 Training Accuracy: 54.5150%\n",
      "Epoch: 15/15 Validation Loss: 1.0265 Validation Accuracy: 46.7000%\n",
      "Original Model Performance:\n",
      "Accuracy: 53.30%\n",
      "F1 Score: 0.5074\n",
      "\n",
      "Model with GLoVe Embeddings Performance:\n",
      "Accuracy: 43.95%\n",
      "F1 Score: 0.3955\n"
     ]
    }
   ],
   "source": [
    "### WRITE YOUR OWN CODE BELOW\n",
    "# Create an instance of the FFTextClassifierWithEmbeddings class\n",
    "ff_classifier_with_embeddings = FFTextClassifierWithEmbeddings(hidden_size, sequence_length, num_classes, embedding_matrix)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 15\n",
    "\n",
    "trained_model_with_embeddings, train_losses_with_embeddings, dev_losses_with_embeddings = train_nn(num_epochs, ff_classifier_with_embeddings, train_loader, dev_loader)\n",
    "\n",
    "# Test the model\n",
    "gold_labs_embed, pred_labs_embed = predict_nn(trained_model_with_embeddings, test_loader)\n",
    "\n",
    "# Importing Performance metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Original FFTextClassifier performance\n",
    "accuracy = accuracy_score(gold_labs, pred_labs)\n",
    "f1 = f1_score(gold_labs, pred_labs, average='weighted')\n",
    "\n",
    "# FFTextClassifierWithEmbeddings performance\n",
    "accuracy_embed = accuracy_score(gold_labs_embed, pred_labs_embed)\n",
    "f1_embed = f1_score(gold_labs_embed, pred_labs_embed, average='weighted')\n",
    "\n",
    "print(\"Original Model Performance:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))\n",
    "\n",
    "print(\"\\nModel with GLoVe Embeddings Performance:\")\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_embed * 100))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_embed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c20d5-12c8-4820-89e2-e53c11b77b42",
   "metadata": {},
   "source": [
    "# 3. Improving the Neural Text Classifier (max. 22 marks)\n",
    "\n",
    "This section allows you some more free reign to experiment with the neural text classifier. Below, we list several to-dos that you can solve in your own way. Please make sure to label your notebook cells clearly so that it is obvious which to-do each cell corresponds to.\n",
    "\n",
    "**TO-DO 3a:** Consider the neural text classifiers we have just implemented and the results you obtained in the last to-do. The classifiers have a number of limitations that we could improve. Describe three limitations and how you could improve them. For each improvement you propose, provide a brief explanation (up to 1 paragraph) of how it works. \n",
    "\n",
    "Hint: refer to the lectures for some ideas. **(9 marks)**\n",
    "\n",
    "WRITE YOUR ANSWER HERE:\n",
    "\n",
    "One limitation of the neural neural text classifiers is that they may encounter words in the test or validation data that were not present in the training data, resulting in OOV words. To improve this, we can use subword tokenisation techniques like Byte-Pair Encoding (BPE) or WordPiece tokenisation. These techniques break words into subword units and allow the model to handle OOV words by composing them from known subwords. This helps in capturing the meaning of new or rare words that were not present in the training data.\n",
    "\n",
    "Another limitation is the potential for overfitting to the training data, therefore performing bad on unseen data. This can be addressed by applying regularisation techniques such as dropout or weight decay. Dropout randomly sets a fraction of the activations to zero during training, which helps in preventing the model from relying too heavily on specific features or relationships in the training data. Weight decay adds a penalty term to the loss function, discouraging large weights and promoting a simpler model.\n",
    "\n",
    "Finally, another limitation is the variability and instablility of the neural text classifiers, that can promote biases or weaknesses. To address this, we can use ensemble methods, where we can train multiple neural text classifiers with different architectures or random initialisations and combine their predictions. This can help in reducing model bias and variance, leading to improved performance. Ensemble methods also provide better model uncertainty estimation by considering the diversity of prediction from different models. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**TO-DO 3b:** Implement your improvements and compute the performance of your method. Make sure to comment your code to show where each new step is implemented. Use the validation set for any tuning you decide to do. Present your results clearly. **(13 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e99e0d0d-ac93-4f7b-8169-c81f6b151eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d3220a215d443fb432efab22057c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b378eaa4424b5cb30ad5eaa257a258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing pretrained tokenizer from Transformers package\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Handling OOV Words\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize and encode the text using the tokenizer\n",
    "train_encoded = train_dataset.map(lambda sample: {'input_ids': tokenizer.encode(sample['text'], truncation=True, padding='max_length', max_length=sequence_length), 'label': sample['label']})\n",
    "dev_encoded = dev_dataset.map(lambda sample: {'input_ids': tokenizer.encode(sample['text'], truncation=True, padding='max_length', max_length=sequence_length), 'label': sample['label']})\n",
    "\n",
    "# Update the vocab size based on the tokenizer\n",
    "vocab_size = len(tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e921ef0",
   "metadata": {},
   "source": [
    "Here I am addressing the first limitation by using a subword tokenisation technique provided by the transformers library. This replaces the CountVectorizer for encoding the text. I have used a pre-trained tokeniser and tokenised the text into subwords. The vocabulary size of the modelwill be adjusted accordingly based on the tokeniser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e126a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FFTextClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, sequence_length, embedding_size, hidden_size, num_classes):\n",
    "        super(FFTextClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # Here we just need to construct the components of our network. We don't need to connect them together yet.\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_size) # embedding layer\n",
    "        \n",
    "        ### COMPLETE THE CODE HERE: WRITE IN THE MISSING ARGUMENTS SPECIFYING THE DIMENSIONS OF EACH LAYER\n",
    "        self.hidden_layer = nn.Linear(sequence_length*embedding_size, hidden_size) # Fully connected hidden layer\n",
    "        self.activation = nn.ReLU() # Hidden layer\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes) # Fully connected output layer\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2) # Dropout layer with 20% dropout rate\n",
    "        \n",
    "    def forward (self, input_words):\n",
    "        # Input dimensions are:  (batch_size, seq_length)\n",
    "        embedded_words = self.embedding_layer(input_words)  # (batch_size, seq_length, embedding_size)\n",
    "\n",
    "        # flatten the sequence of embedding vectors for each document into a single vector.\n",
    "        embedded_words = embedded_words.reshape(embedded_words.shape[0], sequence_length*self.embedding_size)  # batch_size, seq_length*embedding_size\n",
    "\n",
    "        z = self.hidden_layer(embedded_words)   # (batch_size, seq_length, hidden_size)\n",
    "        z = self.dropout(self.hidden_layer(embedded_words)) #applying dropout to the hidden layer output\n",
    "        \n",
    "        h = self.activation(z)\n",
    "\n",
    "        output = self.output_layer(h)                      # (batch_size, num_classes)\n",
    "\n",
    "        # Notice we haven't applied a softmax activation to the output layer -- it's not required by Pytorch's loss function.\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626bfc02",
   "metadata": {},
   "source": [
    "In this code I am addressing the second limitation by adding model regularisation through using dropout. I have added dropout regularisation to the hidden layer of the neural network which can help prevent overfitting and improve generalisation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8243e11d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_models):\n\u001b[1;32m     20\u001b[0m     model \u001b[38;5;241m=\u001b[39m FFTextClassifier(vocab_size, sequence_length, embedding_size, hidden_size, num_classes)\n\u001b[0;32m---> 21\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(trained_model)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Call the ensemble function to compute the performance on the validation dataset\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m, in \u001b[0;36mtrain_nn\u001b[0;34m(num_epochs, model, train_dataloader, dev_dataloader)\u001b[0m\n\u001b[1;32m     15\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# Put the model in training mode.\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (batch_input_ids, batch_labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(batch_input_ids)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#defining a function that evaluates the performance of the ensemble methods on the validation set\n",
    "def run_ensemble(models, val_loader):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for val_input_ids, val_labels in val_loader:\n",
    "        output = ensemble_predict(models, val_input_ids)\n",
    "        predicted_labels = output.argmax(1)\n",
    "        total_correct += (predicted_labels == val_labels).sum().item()\n",
    "        total_samples += val_labels.size(0)\n",
    "\n",
    "    val_accuracy = total_correct / total_samples * 100\n",
    "\n",
    "    print(\"Validation Accuracy: {:.4f}%\".format(val_accuracy))\n",
    "\n",
    "# Model Ensemble\n",
    "num_models = 5\n",
    "models = []\n",
    "for _ in range(num_models):\n",
    "    model = FFTextClassifier(vocab_size, sequence_length, embedding_size, hidden_size, num_classes)\n",
    "    trained_model = train_nn(num_epochs, model, train_encoded, dev_encoded)\n",
    "    models.append(trained_model)\n",
    "\n",
    "# Call the ensemble function to compute the performance on the validation dataset\n",
    "val_encoded = dev_dataset.map(lambda sample: {'input_ids': tokenizer.encode(sample['text'], truncation=True, padding='max_length', max_length=sequence_length), 'label': sample['label']})\n",
    "val_loader = convert_to_data_loader(val_encoded, num_classes)\n",
    "\n",
    "run_ensemble(models, val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e9cf5",
   "metadata": {},
   "source": [
    "Here I have made an attempt to address my third and final limitation of variability and instability in the neural text classifier. I have made an attempt to try and train multiple text classifiers with diffrent random initialisations and combining their predictions by averaging the output probabilities. This is much harder to implement compared to the other improvements as it requires changing a lot more of the previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78cd93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
